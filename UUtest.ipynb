{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c22db62-05bb-4658-a58e-86034582700c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b93d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import flatten\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.stats import t\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12745e2f-c855-4041-b0dd-755383b36f0b",
   "metadata": {},
   "source": [
    "## UU-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03332bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks(X,alpha=0.01):\n",
    "    \"\"\"\n",
    "    Kolmogorov-Smirnov test for uniformity.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like\n",
    "        Sample data.\n",
    "    alpha : float, optional\n",
    "        Significance level (default is 0.01).\n",
    "    \n",
    "    Returns:\n",
    "    int\n",
    "        1 if the null hypothesis (that X follows a uniform distribution) is not rejected at level alpha.\n",
    "        0 otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # If all values in X are the same (min(X) == max(X)), the function returns 1.\n",
    "    if min(X) != max(X):\n",
    "        np.seterr(invalid='ignore')\n",
    "        ktest = stats.kstest(X, cdf='uniform', args=(min(X), max(X) - min(X)), N=len(X))        \n",
    "        pvalue = ktest[1]           \n",
    "        return int(pvalue > alpha)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9286677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gcmlcm(X, plot_on = False):  \n",
    "    \"\"\"\n",
    "    Computes the greatest convex minorant (GCM) and least concave majorant (LCM) \n",
    "    of the empirical cumulative distribution function (ECDF) for a given dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    X : array-like\n",
    "        Input sample data (numerical values).\n",
    "    plot_on : bool, optional\n",
    "        If True, generates a histogram and plots the convex hull visualization (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    gcm : list\n",
    "        List of x-values corresponding to the greatest convex minorant (GCM).\n",
    "    lcm : list\n",
    "        List of x-values corresponding to the least concave majorant (LCM).\n",
    "    \n",
    "    Raises:\n",
    "    ValueError:\n",
    "        If `X` contains fewer than 3 points, as GCM and LCM cannot be computed.\n",
    "    \n",
    "    Notes:\n",
    "    - The function computes the ECDF of `X` and constructs its convex hull.\n",
    "    - The vertices of the convex hull are used to determine GCM and LCM points.\n",
    "    - The first ECDF value is removed to avoid trivial cases.\n",
    "    - If `plot_on=True`, the function visualizes the dataset histogram and convex hull construction.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(X)<3:\n",
    "        print(\"Error!!!! Not enough points to compute gcm and lcm points!! (Need at least 3!)\") \n",
    "        raise ValueError(\"Not enough points\")\n",
    "    else: \n",
    "        X = sorted(X)  \n",
    "        ecdf = ECDF(X)\n",
    "        F, x = ecdf.y,  ecdf.x\n",
    "        F = F[1:]\n",
    "        x = x[1:]         \n",
    "        points = np.array(list(zip(x, F)))\n",
    "        K = ConvexHull(points)        \n",
    "        Kx, gcm, lcm = [], [], []   \n",
    "        Kx = K.vertices.tolist()\n",
    "     \n",
    "    ind_0 = Kx.index(0)\n",
    "    ind_last = Kx.index(len(F)-1)\n",
    "    if ind_0 > ind_last:\n",
    "        lcm_ind = sorted(Kx[ind_last:ind_0])\n",
    "        gcm_ind = sorted([i for i in Kx if i not in lcm_ind])\n",
    "    else:\n",
    "        gcm_ind = sorted(Kx[ind_0:ind_last])\n",
    "        lcm_ind = sorted([i for i in Kx if i not in gcm_ind])\n",
    "    gcm = sorted([X[i] for i in gcm_ind])\n",
    "    lcm = sorted([X[i] for i in lcm_ind]) \n",
    "    \n",
    "    if plot_on:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(X, bins=50)        \n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(x,F,'b-')\n",
    "        plt.plot(x[gcm_ind], F[gcm_ind],'r*', mfc='none', label=\"gcm\")\n",
    "        plt.plot(x[lcm_ind], F[lcm_ind],'go', mfc='none', label=\"lcm\")        \n",
    "        plt.plot(x[gcm_ind], F[gcm_ind],'r--')\n",
    "        plt.plot(x[lcm_ind], F[lcm_ind],'g--')        \n",
    "        plt.plot([x[-1], max(x[gcm_ind])], [F[-1], max(F[gcm_ind])],'r--')\n",
    "        plt.plot([x[0], min(x[lcm_ind])], [F[0], min(F[lcm_ind])],'g--')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return gcm, lcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a00271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_search(PB,eR,X):\n",
    "    \"\"\"\n",
    "    Performs a backward search to refine a partition boundary.\n",
    "\n",
    "    The function iteratively removes elements from the partition boundary (PB) \n",
    "    and checks whether the remaining partition is still uniform \n",
    "    using the Kolmogorov-Smirnov (KS) test. If a valid partition is found, \n",
    "    the boundary is extended to eR, and success is marked.\n",
    "\n",
    "    Parameters:\n",
    "    PB : list\n",
    "        A list representing partition boundaries.\n",
    "    eR : float\n",
    "        The right endpoint of the partition being tested (is stable).\n",
    "    X : array-like\n",
    "        The dataset on which the partitioning is applied.\n",
    "\n",
    "    Returns:\n",
    "    PB : list\n",
    "        The updated partition boundaries after backward search.\n",
    "    success : int\n",
    "        1 if a valid partition is found, 0 otherwise.\n",
    "\n",
    "    Notes:\n",
    "    - The function starts by removing the last element of PB.\n",
    "    - It iterates while PB is not empty, checking if the data subset \n",
    "      between `max(PB)` and `eR` satisfies the KS test (`ks(xx)`).\n",
    "    - If a valid partition is found, `eR` is added back, and success is set to 1.\n",
    "    - If no valid partition is found, PB is returned empty.\n",
    "    \"\"\"\n",
    "    success = 0\n",
    "    del PB[-1]\n",
    "    while PB:\n",
    "        xx = [x for x in X if max(PB) <= x <= eR]\n",
    "        if ks(xx):\n",
    "            PB.append(eR)\n",
    "            success = 1           \n",
    "            return PB, success\n",
    "        del PB[-1]      \n",
    "    return PB, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90529be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_search(PF,eL,X):   \n",
    "    \"\"\"\n",
    "    Performs a forward search to refine a partition boundary.\n",
    "\n",
    "    The function iterates through the partition boundaries (PF) and finds the first \n",
    "    valid boundary satisfying the Kolmogorov-Smirnov (KS) test. If a valid partition \n",
    "    is found, the corresponding boundary is returned along with a success flag.\n",
    "\n",
    "    Parameters:\n",
    "    PF : list\n",
    "        A list representing partition boundaries.\n",
    "    eL : float\n",
    "        The left endpoint of the partition being tested.\n",
    "    X : array-like\n",
    "        The dataset on which the partitioning is applied.\n",
    "\n",
    "    Returns:\n",
    "    PF_ : float or empty list\n",
    "        The selected partition boundary if a valid one is found, otherwise an empty list.\n",
    "    success : int\n",
    "        1 if a valid partition is found, 0 otherwise.\n",
    "    \"\"\"\n",
    "    success = 0    \n",
    "    for point in PF:        \n",
    "        if point > eL:\n",
    "            xx = [x for x in X if eL <= x <= point]        \n",
    "            if ks(xx):\n",
    "                PF_ = point\n",
    "                success = 1                \n",
    "                return PF_, success  \n",
    "    if not success:\n",
    "        PF_ = []\n",
    "    \n",
    "    return PF_, success "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8b0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent(gcm, lcm): \n",
    "    \"\"\"\n",
    "    This function organizes the GCM and LCM points into consistent subsets.\n",
    "    If only one of the sets is provided, it returns that set as a single consistent subset.\n",
    "    If GCM points appear before LCM points without overlap, they are merged into one ordered set.\n",
    "    Otherwise, the function (`determine_consistent_subsets`) is called to separate them into multiple consistent subsets.\n",
    "\n",
    "    Parameters:\n",
    "    gcm : list\n",
    "        A list of x-values corresponding to the greatest convex minorant (GCM).\n",
    "    lcm : list\n",
    "        A list of x-values corresponding to the least concave majorant (LCM).\n",
    "\n",
    "    Returns:\n",
    "    C : list of lists\n",
    "        A list containing one or more subsets of consistent points.\n",
    "    num_of_cons_sets : int\n",
    "        The number of consistent subsets identified.\n",
    "    msg : list of tuples\n",
    "        A list of messages indicating the structure of the returned subsets (type of points).\n",
    "        - If only LCM exists, msg = [('1', [])]\n",
    "        - If only GCM exists, msg = [('0', [])]\n",
    "        - If GCM and LCM are strictly ordered, msg = [('01', len(gcm))]\n",
    "        - Otherwise, msg is determined by `determine_consistent_subsets`.\n",
    "\n",
    "    Notes:\n",
    "    - If both `gcm` and `lcm` exist but are non-overlapping (i.e., `max(gcm) <= min(lcm)`), they are combined into a single sequence.\n",
    "    - Otherwise, `determine_consistent_subsets(gcm, lcm)` is used to find consistent groupings.\n",
    "    \"\"\"\n",
    "    C=[[]]\n",
    "    ind=[[],[]]\n",
    "    num_of_cons_sets = 1\n",
    "    \n",
    "    # no gcm points or lcm starts first\n",
    "    if not gcm:\n",
    "        C[0] = lcm\n",
    "        ind[0]=[1]*len(lcm)\n",
    "        msg=[('1',[])]\n",
    "    elif not lcm:\n",
    "        C[0] = gcm\n",
    "        ind[0]=[0]*len(gcm)\n",
    "        msg=[('0',[])]\n",
    "    elif max(gcm)<=min(lcm):\n",
    "        C[0] = gcm+lcm\n",
    "        ind[0] = [0]*len(gcm) + [1]*len(lcm)\n",
    "        msg=[('01',len(gcm))]\n",
    "    else:\n",
    "        C,num_of_cons_sets,msg = determine_consistent_subsets(gcm,lcm)  \n",
    "    return C, num_of_cons_sets, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53a6b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_consistent_subsets(gcm,lcm):\n",
    "    \"\"\"\n",
    "    Creates consistent subsets of the ordered gcm+lcm list.\n",
    "    \n",
    "    The function takes two lists of points, `gcm` (greatest convex minorant) and `lcm`\n",
    "    (least concave majorant), sorts them together, and partitions them into separate \n",
    "    consistent subsets by removing lcm points existing between gcm points.\n",
    "    \n",
    "    Parameters:\n",
    "    gcm : list\n",
    "        A list of x-values corresponding to the greatest convex minorant (GCM).\n",
    "    lcm : list\n",
    "        A list of x-values corresponding to the least concave majorant (LCM).\n",
    "    \n",
    "    Returns:\n",
    "    C : list of lists\n",
    "        A list containing one or more subsets of consistent points.\n",
    "    num_of_cons_sets : int\n",
    "        The number of consistent subsets identified.\n",
    "    msg : list of lists\n",
    "        A list indicating the start index of LCM in each subset.\n",
    "    \"\"\"\n",
    "    gcmlcm = sorted(gcm+lcm)\n",
    "    type_ = list(map(lambda x: 1 if x in lcm else 0, gcmlcm))\n",
    "    ind_last_0s = [i for i in range(len(type_)-1) if type_[i] == 0 and type_[i+1]==1]\n",
    "    num_of_cons_sets = len(ind_last_0s)\n",
    "    C=[[] for _ in range(num_of_cons_sets)]\n",
    "    \n",
    "    msg = [['01',0] for i in range(num_of_cons_sets)]\n",
    "    \n",
    "    for j in range(num_of_cons_sets):\n",
    "        for i in range(len(type_)):\n",
    "            if i<=ind_last_0s[j]:\n",
    "                if type_[i]!=1:\n",
    "                    C[j].append(gcmlcm[i])\n",
    "            else:\n",
    "                if type_[i]!=0:\n",
    "                    C[j].append(gcmlcm[i])\n",
    "        msg[j][1] = min([i for i in range(len(C[j])) if C[j][i] in lcm])\n",
    "    return C, num_of_cons_sets, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42f0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sufficient(P,X):   \n",
    "    \"\"\"\n",
    "    Checks if a partition P is sufficient for the dataset X and refines it if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    P : list\n",
    "        List of partition points.\n",
    "    X : list\n",
    "        List of data points.\n",
    "\n",
    "    Returns:\n",
    "    P_ : list\n",
    "        A refined partition satisfying the sufficiency condition.\n",
    "    success : int\n",
    "        1 if a sufficient partition is found, 0 otherwise.\n",
    "    notUU : list\n",
    "        Intervals where sufficiency fails.\n",
    "    \"\"\"\n",
    "    notUU=[]; success = 1\n",
    "    xx = [x for x in X if P[0] <= x <= P[-1]] \n",
    "    if ks(xx):     \n",
    "        P_=[P[0],P[-1]]\n",
    "        return P_, success, notUU\n",
    "    eL = P[0]\n",
    "    P_ = [eL]   \n",
    "    \n",
    "    while max(P_) != max(P):\n",
    "        eR = min([x for x in P if x > max(P_)])\n",
    "        xx = [x for x in X if eL <= x <= eR]\n",
    "        if ks(xx):\n",
    "            P_.append(eR)\n",
    "        else:\n",
    "            PF, success = Forward_search(P, eL,X)\n",
    "            if success:\n",
    "                P_.append(PF)\n",
    "            else:\n",
    "                PB, success = Backward_search(P_, eR , X)\n",
    "                if not success:\n",
    "                    #\n",
    "                    notUU.append([eL, eR])\n",
    "                    P_.append(eR)\n",
    "                else:\n",
    "                    P_ = PB\n",
    "        eL = max(P_)\n",
    "    if notUU:\n",
    "        P_ = []\n",
    "        success = 0\n",
    "    return P_, success, notUU   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66f5fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UU(SG,PI,SL,X,plot_on, detect_peaks):\n",
    "    \n",
    "    \"\"\"\n",
    "    Recursive function to create a piecewise linear unimodal approximation (PL_S(X)) of the ecdf of X\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    SG : list\n",
    "        List of gcm points\n",
    "    PI : list\n",
    "        Middle part (last gcm to first lcm)\n",
    "    SL : list\n",
    "        List of lcm points\n",
    "    X : list\n",
    "        The dataset (assumed to be a 1D list of numerical values).\n",
    "    plot_on : bool\n",
    "        If True, enables visualization.\n",
    "    detect_peaks : bool\n",
    "        If True, it aims to find the peak of the data (works for unimodal datasets only!)\n",
    "        Then no recursion calls occur for the middle part, and returns the middle part unchanged.\n",
    "        The mean value of the middle part can be used to compute the peak.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    SG_ : list\n",
    "        Updated list of gcm points, where each segment is uniform.\n",
    "    PI_ : list\n",
    "        Updated middle part.\n",
    "    SL_ : list\n",
    "        Updated list of lcm points, where each segment is uniform.\n",
    "    success : int\n",
    "        Indicator of success (1 if approximation was found, 0 otherwise).\n",
    "    notUU : list\n",
    "        List of segments that were found to be **not unimodal/not uniform**.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = sorted(X)    \n",
    "    SG_ = SG\n",
    "    SL_ = SL\n",
    "    notUU, PG, PL = [], [], []\n",
    "    xx = [x for x in X if PI[0] <= x <= PI[1]]    \n",
    "    if ks(xx):        \n",
    "        success = 1\n",
    "        return SG_,PI,SL_,success,notUU\n",
    "    \n",
    "    gcm, lcm = compute_gcmlcm(xx,plot_on)\n",
    "    C, num_of_cons_sets, msg = consistent(gcm,lcm)\n",
    "\n",
    "    if not num_of_cons_sets:\n",
    "        success = 1       \n",
    "        PI_ = [min(X),max(X)]\n",
    "        SG_ = SG_ + []\n",
    "        SL_ = SL_ + []\n",
    "        \n",
    "    for i in range(num_of_cons_sets):\n",
    "        type_of_GL, ind_of1 = msg[i]\n",
    "        \n",
    "        if type_of_GL == '01':\n",
    "            PG=C[i][:ind_of1]\n",
    "            PL=C[i][ind_of1:]\n",
    "            PI_=[max(PG),min(PL)]\n",
    "            PG_, success, notUU_ = sufficient(PG,X)\n",
    "  \n",
    "            if not success:\n",
    "                notUU.extend([x + y for x, y in zip(notUU_, [[0]]*len(notUU_))])\n",
    "                continue       \n",
    "            PL_, success, notUU_ = sufficient(PL,X)\n",
    "      \n",
    "            if not success:\n",
    "                notUU.extend([x + y for x, y in zip(notUU_, [[1]]*len(notUU_))])\n",
    "                continue\n",
    "            SG_= SG_ + PG_\n",
    "            SL_ = SL_ + PL_\n",
    "            \n",
    "        elif type_of_GL == '0': \n",
    "            PG = C[i][0]\n",
    "            PI_ = []\n",
    "            PG_, success, notUU_ = sufficient(PG,X)\n",
    "       \n",
    "            if not success:\n",
    "                notUU.extend([x + y for x, y in zip(notUU_, [[0]]*len(notUU_))])\n",
    "                continue             \n",
    "            SG_= SG_ + PG_\n",
    "            \n",
    "        else:\n",
    "            PI_ = []\n",
    "            PL = C[i][0]\n",
    "            PL_, success, notUU_ = sufficient(PL,X)\n",
    "           \n",
    "            if not success:\n",
    "                notUU.extend([x + y for x, y in zip(notUU_, [[1]]*len(notUU_))])\n",
    "                continue         \n",
    "            SL_ = SL_ + PL_\n",
    "\n",
    "        if success:\n",
    "            if PI_:\n",
    "                if detect_peaks: return SG_,PI_,SL_,success,notUU\n",
    "                SG_,PI_,SL_,success,notUU_ = UU(SG_,PI_,SL_,X,plot_on, detect_peaks)\n",
    "\n",
    "                if not success:\n",
    "                    notUU.extend(notUU_)\n",
    "                    continue\n",
    "            return SG_,PI_,SL_,success,notUU\n",
    "        \n",
    "    if not success:\n",
    "        PI_, SG_, SL_ = [], [], []        \n",
    "         \n",
    "    return SG_,PI_,SL_,success,notUU               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f136a74-9cd5-45b5-b9f5-4972198db91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UUtest(X, plot_on = False, detect_peaks = False):   \n",
    "    \"\"\"\n",
    "    Wrapper function for the UU method to create a piecewise linear unimodal approximation of the ecdf of X.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a 1D list of numerical values).\n",
    "    plot_on : bool, optional\n",
    "        If True, enables visualization.\n",
    "    detect_peaks : bool, optional\n",
    "        If True, it detects the peak of X (working on unimodal datasets only!).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    S : list\n",
    "        Sorted list of segment boundaries (unimodal partitions).\n",
    "    notUU : list\n",
    "        List of segments that were found to be not uniform.\n",
    "    success : int\n",
    "        Indicator of success (1 if approximation was found, 0 otherwise).\n",
    "    PI_ : list\n",
    "        Middle part of the unimodal piecewise linear approximation if `detect_peaks` is enabled, otherwise an empty list.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not X:\n",
    "        print(\"Empty dataset\") \n",
    "        raise ValueError(\"Empty dataset\")\n",
    "    X=sorted(X) \n",
    "#     X = add_unif_noise(X)\n",
    "#     print(f'X={X}')\n",
    "    SG, SL = [], []    \n",
    "    PI=[min(X), max(X)]  \n",
    "    SG_,PI_,SL_,success,notUU = UU(SG,PI,SL,X,plot_on, detect_peaks)\n",
    "    S=sorted(list(set(SG_ + PI_ + SL_)))\n",
    "    if success: notUU = []\n",
    "    if detect_peaks: return S, notUU, success, PI_\n",
    "    return S, notUU, success, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29117179-0629-4175-bf6b-c1c6519ad7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_unif_noise(f):\n",
    "# add uniform noise into the data (e.g., in case of discrete values)\n",
    "# # X1 = X[:,0].tolist()\n",
    "#     from collections import Counter\n",
    "#     cnt = Counter(f)\n",
    "#     data_to_change = [k for k, v in cnt.items() if v > 1]\n",
    "#     if not data_to_change:\n",
    "#         return f\n",
    "#     sumi=0\n",
    "#     for i in range(len(f)):\n",
    "#         if f[i] in data_to_change:        \n",
    "#             noise = np.random.uniform(-0.01,0.01,1)\n",
    "#             f[i] += noise[0]\n",
    "#             sumi+=1\n",
    "#     return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba4c57-a20f-418e-9045-775b87ee7637",
   "metadata": {},
   "source": [
    "## Functions for Uniform Mixture Modeling (UMM) and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61f7777-28c1-4fc3-b37e-bc8620ce7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_in_interval(X, S):\n",
    "    \"\"\"\n",
    "    Computes the proportion of data points that fall within each interval defined in S.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a sorted 1D list of numerical values).\n",
    "    S : list\n",
    "        A sorted list of boundary points (of the determined PL_S(X)) defining intervals.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    p : list\n",
    "        A list of percentages representing the proportion of X in each interval.\n",
    "    \"\"\"\n",
    "    if len(S) == 1: return [1]\n",
    "    count = []\n",
    "    for i in range(len(S)-1):\n",
    "        count.append(len([x for x in X if S[i] < x <= S[i+1]]))\n",
    "    count[0] = count[0] + 1\n",
    "    p = [x / len(X) for x in count]\n",
    "    return p\n",
    "\n",
    "def fitUU(X):\n",
    "    \"\"\"\n",
    "    Fits a unimodal piecewise linear cdf to the dataset's ecdf.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a 1D list of numerical values).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    component_point_ratio : list\n",
    "        A list containing the proportion of points belonging to each component\n",
    "        (here: 1 unimodal component (to do: multiple unimodal components)\n",
    "    interval_point_ratio : list\n",
    "        A list of lists, where each sublist contains the proportion of points in each interval.\n",
    "    intervals_per_component : list\n",
    "        A list containing the interval boundaries for each detected unimodal component.\n",
    "    component_ranges : list\n",
    "        A list containing the global range [min(X), max(X)].\n",
    "    \"\"\"\n",
    "    intervals_per_component = []\n",
    "    S, _ , _, _ = UUtest(X)\n",
    "    if S:\n",
    "        #print('unimodal')\n",
    "        component_point_ratio = [1]\n",
    "        interval_point_ratio = [calculate_percentage_in_interval(X,S)]\n",
    "        intervals_per_component.append(S)\n",
    "        component_ranges = [min(X), max(X)]\n",
    "    else:\n",
    "        print(\"The dataset is multimodal. No fit is achieved.\")\n",
    "    return component_point_ratio, interval_point_ratio, intervals_per_component, component_ranges\n",
    "    \n",
    "def locate_point_in_interval(x, ranges):   \n",
    "    \"\"\"\n",
    "    Locates which interval in 'ranges' the given point 'x' falls into.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    x : float\n",
    "        The data point to locate.\n",
    "    ranges : list\n",
    "        A sorted list of boundary points defining intervals.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    index : int\n",
    "        The index of the interval in which 'x' falls.\n",
    "        Returns -2 if 'x' is below the lowest interval.\n",
    "        Returns -1 if 'x' is above the highest interval.\n",
    "    \"\"\"\n",
    "    if x < ranges[0]:\n",
    "        return -2            \n",
    "    elif x > ranges[-1]:\n",
    "        return -1                \n",
    "    for i in range(len(ranges)-1):        \n",
    "        if ranges[i] <= x <= ranges[i+1]:           \n",
    "            return i       \n",
    "\n",
    "def cdfUU(X, S, p):\n",
    "    \"\"\"\n",
    "    Computes the cumulative distribution function (CDF) for a unimodal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a sorted 1D list of numerical values).\n",
    "    S : list\n",
    "        A sorted list of interval boundaries.\n",
    "    p : list\n",
    "        The proportion of points in each interval.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    y : list\n",
    "        The CDF values corresponding to the sorted dataset X.\n",
    "    X : list\n",
    "        The sorted dataset.\n",
    "    \"\"\"\n",
    "    X = sorted(X)    \n",
    "    y = []\n",
    "    for i in range(len(X)):\n",
    "        ind = locate_point_in_interval(X[i], S)   \n",
    "        if ind == -2:           \n",
    "            y.append(0)\n",
    "        elif ind == -1:\n",
    "            y.append(1)          \n",
    "        else: \n",
    "            y_val = sum(p[:ind]) + p[ind] * (X[i]-S[ind]) / (S[ind+1]-S[ind])               \n",
    "            y.append(y_val)        \n",
    "    return y, X\n",
    "\n",
    "\n",
    "def pdfUU(X, component_point_ratio, interval_point_ratio, intervals_per_component, component_ranges):\n",
    "    \"\"\"\n",
    "    Computes the probability density function (PDF) for a given unimodal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a sorted 1D list of numerical values).\n",
    "    component_point_ratio : list\n",
    "        Proportion of points in each component.\n",
    "    interval_point_ratio : list\n",
    "        A list of proportions of points in each interval.\n",
    "    intervals_per_component : list\n",
    "        A list containing the interval boundaries for each detected unimodal component.\n",
    "    component_ranges : list\n",
    "        The global range of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pdf_val : list\n",
    "        The computed PDF values for each point in X.\n",
    "    X : list\n",
    "        The sorted dataset.\n",
    "    \"\"\"\n",
    "    X = sorted(X)\n",
    "    pdf_val = []\n",
    "    point_ind = [locate_point_in_interval(x, component_ranges) for x in X]\n",
    "    for i in range(len(X)):\n",
    "        if point_ind[i] < 0:            \n",
    "            pdf_val.append(0)\n",
    "            continue\n",
    "            \n",
    "        pdfUU_of_x = pdfUU_of_point(X[i], intervals_per_component[point_ind[i]], interval_point_ratio[point_ind[i]])        \n",
    "        pdf_val.append(component_point_ratio[point_ind[i]] * pdfUU_of_x)\n",
    "    return pdf_val, X\n",
    "\n",
    "\n",
    "def pdfUU_of_point(x, S, p):\n",
    "    \"\"\"\n",
    "    Computes the probability density function (PDF) value for a single point 'x'.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    x : float\n",
    "        The data point for which to compute the PDF.\n",
    "    S : list\n",
    "        A sorted list of interval boundaries.\n",
    "    p : list\n",
    "        The proportion of points in each interval.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pdf_val : float\n",
    "        The computed PDF value for the given point 'x'.\n",
    "    \"\"\"\n",
    "    i = locate_point_in_interval(x, S)\n",
    "    if i<0: return 0\n",
    "    pdf_val = p[i] / (S[i+1] - S[i])\n",
    "    return pdf_val\n",
    "\n",
    "\n",
    "def sample(X, n):\n",
    "    \"\"\"\n",
    "    Generates 'n' samples from the estimated unimodal distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    X : list\n",
    "        The dataset (assumed to be a sorted 1D list of numerical values).\n",
    "    n : int\n",
    "        The number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    samples : list\n",
    "        A list of generated samples following the estimated unimodal distribution.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    component_point_ratio, interval_point_ratio, intervals_per_component, _ = fitUU(X)\n",
    "    for j in range(len(component_point_ratio)):    \n",
    "        random_val = np.random.multinomial(round(component_point_ratio[j] * n), interval_point_ratio[j])\n",
    "        S = intervals_per_component[j]    \n",
    "        for i in range(len(S)-1):\n",
    "            random_num = [(S[i+1]-S[i]) * random.random() for _ in range(random_val[i])]\n",
    "            samples.extend([S[i] + x for x in random_num])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183330ef-dadd-43bf-96f8-14429d3c4bd4",
   "metadata": {},
   "source": [
    "## Demo - Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "063882ef-5296-4d5e-9281-01269c97cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Demo(dip_test = True, UMM = True, generate_sample = True):\n",
    "\n",
    "\n",
    "    # Unimodal case\n",
    "    X = np.random.normal(0, 1, 1500)\n",
    "\n",
    "    ## Multimodal case (uncomment)\n",
    "    # X1 = np.random.normal(0, 1, 1000)\n",
    "    # X2 = np.random.normal(5,1,500)\n",
    "    # X3 = np.random.uniform(15,20,700)\n",
    "    # X = np.concatenate((X1, X2, X3))\n",
    "    \n",
    "    \n",
    "    # Run the unimodality test\n",
    "    X = X.tolist()\n",
    "    S, notUU, success, _ = UUtest(X, plot_on = True, detect_peaks = False)\n",
    "    \n",
    "    if success:\n",
    "        print(\"* A piecewise linear approximation of the ecdf of your dataset has been successfully determined.\\n\")\n",
    "        print(\"* Your dataset is unimodal.\\n\")\n",
    "        print(f\"* The points that define the approximation cdf are saved in S\\n\\n S: {S}\\n\")\n",
    "    \n",
    "        # For detecting the peak\n",
    "        _, _, _, PI_ = UUtest(X, plot_on = False, detect_peaks = True)\n",
    "        # mean or median value can be used\n",
    "        peak = np.mean(PI_)\n",
    "        print(f\"The peak of your dataset is: {peak}\\n\")\n",
    "    \n",
    "    else:\n",
    "        notUU_indicator = {0: \"gcm\", 1:\"lcm\"}\n",
    "        print(\"* No unimodal piecewise linear approximation of the ecdf of your dataset can be determined.\\n\")\n",
    "        print(\"* Your dataset is multimodal.\\n\")\n",
    "        print(\"* The cause of multimodality is the segment/segments in notUU, i.e.,\\n\")\n",
    "        for segment in notUU:\n",
    "            print(f\"segment: {segment[:2]} defined by '{notUU_indicator[segment[2]]}' points.\\n\")\n",
    "\n",
    "\n",
    "        # Compare with Hartigans' dip-test\n",
    "        # pip install diptest\n",
    "    if dip_test:    \n",
    "        import diptest\n",
    "        dip, pval = diptest.diptest(np.array(X))\n",
    "        print(f\"Hartigans' dip test p-value = {pval}\")\n",
    "\n",
    "    if success:    \n",
    "        if UMM:        \n",
    "            # Fit the unimodal model (only applicable if the dataset is unimodal)\n",
    "                component_point_ratio, interval_point_ratio, intervals_per_component, component_ranges = fitUU(X)\n",
    "            \n",
    "            # Compute and plot the pdf and cdf of the PL_S approximation            \n",
    "                plt.figure(figsize=(16,4))\n",
    "                plt.subplot(1,3,1)\n",
    "                pdf_val, X = pdfUU(X, component_point_ratio, interval_point_ratio, intervals_per_component, component_ranges)\n",
    "                plt.hist(X, bins=50, density = True)\n",
    "                plt.plot(X, pdf_val, 'r', label=\"UMM\")\n",
    "                plt.title(\"Unimodal Mixture Model (UMM)\")\n",
    "                plt.legend()\n",
    "                \n",
    "                ecdf = ECDF(X)\n",
    "                plt.subplot(1,3,2)\n",
    "                cdf_val, X= cdfUU(X,S,interval_point_ratio[0])\n",
    "                plt.plot(X, cdf_val, 'r', label='cdfUU')\n",
    "                plt.plot(ecdf.x, ecdf.y, c='b', label='ecdf')\n",
    "                plt.legend(['cdf','ecdf'])\n",
    "                \n",
    "                plt.subplot(1,3,3)\n",
    "                cdf_val, S= cdfUU(S,S,interval_point_ratio[0])\n",
    "                plt.plot(ecdf.x, ecdf.y, c='b')\n",
    "                plt.plot(S, cdf_val, 'ro--')\n",
    "                plt.legend(['ecdf', 'cdf'])\n",
    "                plt.show()\n",
    "    \n",
    "        # Generate a sample from the original dataset X following the same unimodal distribution \n",
    "        if generate_sample:\n",
    "                \n",
    "            size = 1000\n",
    "            data_sample = sample(X, size)\n",
    "            \n",
    "            plt.figure(figsize=(10,8))\n",
    "            plt.subplot(2,2,1)\n",
    "            plt.hist(X, bins=50)\n",
    "            plt.title(\"Original\")\n",
    "            \n",
    "            plt.subplot(2,2,3)\n",
    "            ecdf = ECDF(X)\n",
    "            plt.plot(ecdf.x, ecdf.y, c='b', label='ecdf')\n",
    "            \n",
    "            plt.subplot(2,2,2)\n",
    "            plt.hist(data_sample, bins=50)\n",
    "            plt.title(\"Sample\")\n",
    "            \n",
    "            plt.subplot(2,2,4)\n",
    "            ecdf = ECDF(data_sample)\n",
    "            plt.plot(ecdf.x, ecdf.y, c='m', label='ecdf')\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00503486-c5d5-4844-b29d-b04a11aca6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_Demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
